<!DOCTYPE html>
<html lang="id">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>
      Document Similarity Analyzer - Sentence-Level Plagiarism Detection
    </title>

    <!-- KaTeX for Math Rendering -->
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"
    />
    <script
      defer
      src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"
    ></script>
    <script
      defer
      src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
      onload="renderMathInElement(document.body, {
        delimiters: [
          {left: '$$', right: '$$', display: true},
          {left: '$', right: '$', display: false}
        ]
      });"
    ></script>

    <!-- Highlight.js for Code Syntax -->
    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github.min.css"
    />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/rust.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/bash.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/json.min.js"></script>
    <script>
      hljs.highlightAll();
    </script>

    <style>
      :root {
        --primary: #2563eb;
        --secondary: #64748b;
        --success: #10b981;
        --background: #ffffff;
        --text: #1e293b;
        --border: #e2e8f0;
        --code-bg: #f8fafc;
      }

      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }

      body {
        font-family: "Segoe UI", Tahoma, Geneva, Verdana, sans-serif;
        line-height: 1.8;
        color: var(--text);
        background: var(--background);
        max-width: 1000px;
        margin: 0 auto;
        padding: 40px 20px;
      }

      h1 {
        font-size: 2.5rem;
        color: var(--primary);
        margin-bottom: 0.5rem;
        border-bottom: 4px solid var(--primary);
        padding-bottom: 10px;
      }

      h1 + p {
        font-size: 1.1rem;
        color: var(--secondary);
        font-style: italic;
        margin-bottom: 0.5rem;
      }

      h2 {
        font-size: 2rem;
        color: var(--primary);
        margin: 2.5rem 0 1rem 0;
        border-bottom: 2px solid var(--border);
        padding-bottom: 8px;
      }

      h3 {
        font-size: 1.5rem;
        color: var(--text);
        margin: 2rem 0 1rem 0;
      }

      h4 {
        font-size: 1.25rem;
        color: var(--text);
        margin: 1.5rem 0 0.75rem 0;
      }

      p {
        margin-bottom: 1rem;
        text-align: justify;
      }

      strong {
        color: var(--primary);
        font-weight: 600;
      }

      .author {
        color: var(--secondary);
        font-size: 0.95rem;
        margin-bottom: 2rem;
      }

      ul,
      ol {
        margin: 1rem 0 1rem 2rem;
        line-height: 1.8;
      }

      li {
        margin-bottom: 0.5rem;
      }

      table {
        width: 100%;
        border-collapse: collapse;
        margin: 1.5rem 0;
        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);
      }

      th {
        background: var(--primary);
        color: white;
        padding: 12px;
        text-align: left;
        font-weight: 600;
      }

      td {
        padding: 10px 12px;
        border: 1px solid var(--border);
      }

      tr:nth-child(even) {
        background: #f9fafb;
      }

      tr:hover {
        background: #f1f5f9;
      }

      pre {
        background: var(--code-bg);
        border: 1px solid var(--border);
        border-radius: 6px;
        padding: 1.25rem;
        overflow-x: auto;
        margin: 1rem 0;
        font-size: 0.9rem;
      }

      code {
        font-family: "Courier New", monospace;
        font-size: 0.9em;
      }

      :not(pre) > code {
        background: var(--code-bg);
        padding: 2px 6px;
        border-radius: 3px;
        color: #c7254e;
      }

      .abstract-box {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 2rem;
        border-radius: 8px;
        margin: 2rem 0;
        box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
      }

      .abstract-box h2 {
        color: white;
        border-bottom: 2px solid rgba(255, 255, 255, 0.3);
        margin-top: 0;
      }

      .abstract-box p {
        color: rgba(255, 255, 255, 0.95);
      }

      .diagram-box {
        background: #f8fafc;
        border-left: 4px solid var(--primary);
        padding: 1.5rem;
        margin: 1.5rem 0;
        border-radius: 4px;
        overflow-x: auto;
      }

      .comparison-table {
        margin: 2rem 0;
      }

      .comparison-table th {
        background: #10b981;
      }

      hr {
        border: none;
        border-top: 3px double var(--border);
        margin: 3rem 0;
      }

      @media print {
        body {
          max-width: 100%;
          padding: 20px;
        }
        h1 {
          page-break-after: avoid;
        }
        pre,
        table {
          page-break-inside: avoid;
        }
      }
    </style>
  </head>
  <body>
    <!-- HEADER -->
    <h1>Document Similarity Analyzer</h1>
    <p>
      <em
        >Sentence-Level Plagiarism Detection dengan Pemrograman Fungsional
        menggunakan Rust</em
      >
    </p>
    <p class="author">
      <strong>Penulis:</strong> Muhammad Fatihul Iqmal, Awal Ramadhani, Vivian
      Marsyanda, Muhammad 'Aaqil S., Muhammad Arsyad A., Cinta Satilla
    </p>

    <hr />

    <!-- ABSTRAK -->
    <div class="abstract-box">
      <h2>Abstrak</h2>
      <p>
        Document Similarity Analyzer adalah layanan backend berbasis Rust untuk
        deteksi plagiarisme dan analisis kesamaan dokumen pada
        <strong>level kalimat</strong>. Berbeda dengan sistem tradisional yang
        menganalisis kesamaan per dokumen, sistem ini mengimplementasikan
        <strong>sentence-level TF-IDF</strong> dan
        <strong>Cosine Similarity</strong> untuk mengidentifikasi
        kalimat-kalimat spesifik yang mirip antar dokumen. Aplikasi ini
        mendukung multi-format file (PDF, DOCX, TXT) dengan upload maksimal 5
        file, menggunakan <strong>Axum</strong> untuk HTTP server dan
        <strong>Rayon</strong> untuk parallel processing. Threshold similarity
        yang dapat dikonfigurasi (default 0.70) memungkinkan fleksibilitas
        antara precision dan recall. Seluruh core logic dibangun dengan prinsip
        <strong>pemrograman fungsional</strong> — pure functions, immutability,
        dan data transformations — menghasilkan kode yang robust, testable, dan
        maintainable.
      </p>
    </div>

    <hr />

    <!-- PENDAHULUAN -->
    <h2>Pendahuluan</h2>

    <h3>Latar Belakang Masalah</h3>
    <p>
      Di era digital, kebutuhan untuk mendeteksi plagiarisme dan menganalisis
      kesamaan dokumen semakin krusial:
    </p>
    <ul>
      <li>
        <strong>Akademik</strong>: Deteksi plagiarisme pada paper, thesis, dan
        tugas mahasiswa
      </li>
      <li>
        <strong>Penelitian</strong>: Identifikasi duplikasi konten dalam
        publikasi ilmiah
      </li>
      <li>
        <strong>Legal</strong>: Analisis kemiripan dokumen dalam kasus hukum
      </li>
      <li>
        <strong>Content Moderation</strong>: Deteksi duplikasi konten online
      </li>
    </ul>

    <p><strong>Masalah Sistem Tradisional:</strong></p>
    <ul>
      <li>
        Analisis per dokumen hanya memberikan skor global (misal: "Dokumen A 78%
        mirip dengan Dokumen B")
      </li>
      <li>Tidak bisa menunjukkan <strong>bagian mana yang mirip</strong></li>
      <li>Sulit untuk memberikan evidence konkret untuk plagiarisme</li>
    </ul>

    <p><strong>Solusi: Sentence-Level Analysis</strong></p>
    <ul>
      <li>
        Identifikasi <strong>kalimat spesifik</strong> yang mirip antar dokumen
      </li>
      <li>Memberikan index sentence untuk highlighting di frontend</li>
      <li>Support multiple file formats (PDF, DOCX, TXT)</li>
    </ul>

    <h3>Mengapa Memilih Rust?</h3>
    <p>Rust dipilih karena keunggulan:</p>
    <ol>
      <li>
        <strong>Memory Safety</strong> — Zero-cost abstractions tanpa garbage
        collector
      </li>
      <li>
        <strong>Performance</strong> — Kecepatan setara C/C++ dengan type safety
        modern
      </li>
      <li>
        <strong>Concurrency</strong> — Parallel processing yang aman dengan
        compile-time guarantees
      </li>
      <li>
        <strong>Ecosystem</strong> — Library berkualitas tinggi (Axum, Rayon,
        Tokio)
      </li>
    </ol>

    <h3>Mengapa Pemrograman Fungsional?</h3>
    <p>Prinsip fungsional sangat cocok untuk data processing pipeline:</p>
    <ul>
      <li>
        <strong>Pure Functions</strong> — Output hanya bergantung pada input, no
        side effects
      </li>
      <li>
        <strong>Immutability</strong> — Data tidak dimutasi, melainkan
        ditransformasi
      </li>
      <li>
        <strong>Composability</strong> — Fungsi kecil dapat digabungkan menjadi
        pipeline kompleks
      </li>
      <li>
        <strong>Testability</strong> — Pure functions mudah ditest karena
        deterministik
      </li>
      <li>
        <strong>Parallelization</strong> — Immutable data aman untuk parallel
        processing tanpa locks
      </li>
    </ul>

    <h3>Keunikan Solusi</h3>
    <p>Proyek ini menggabungkan:</p>
    <ul>
      <li>
        <strong>Sentence-level granularity</strong> untuk deteksi plagiarisme
        presisi
      </li>
      <li>Pipeline fungsional murni untuk text processing</li>
      <li>
        <strong>Multipart file upload</strong> dengan validasi komprehensif
      </li>
      <li>
        <strong>Configurable threshold</strong> untuk fleksibilitas use case
      </li>
      <li>REST API stateless yang mudah diintegrasikan</li>
      <li>
        Response yang include <strong>sentence text</strong> untuk frontend
        highlighting
      </li>
    </ul>

    <hr />

    <!-- LATAR BELAKANG DAN KONSEP -->
    <h2>Latar Belakang dan Konsep</h2>

    <h3>Technology Stack</h3>
    <table>
      <thead>
        <tr>
          <th>Teknologi</th>
          <th>Versi</th>
          <th>Fungsi</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td><strong>Rust</strong></td>
          <td>Edition 2021</td>
          <td>Bahasa pemrograman utama</td>
        </tr>
        <tr>
          <td><strong>Axum</strong></td>
          <td>0.7</td>
          <td>HTTP web framework</td>
        </tr>
        <tr>
          <td><strong>Tokio</strong></td>
          <td>1.0</td>
          <td>Async runtime</td>
        </tr>
        <tr>
          <td><strong>Rayon</strong></td>
          <td>1.8</td>
          <td>Parallel data processing</td>
        </tr>
        <tr>
          <td><strong>Serde</strong></td>
          <td>1.0</td>
          <td>Serialization/deserialization JSON</td>
        </tr>
        <tr>
          <td><strong>pdf-extract</strong></td>
          <td>0.7</td>
          <td>PDF text extraction</td>
        </tr>
        <tr>
          <td><strong>docx-rs</strong></td>
          <td>0.4</td>
          <td>DOCX text extraction</td>
        </tr>
        <tr>
          <td><strong>regex</strong></td>
          <td>1.10</td>
          <td>Sentence splitting</td>
        </tr>
        <tr>
          <td><strong>tower-http</strong></td>
          <td>0.5</td>
          <td>HTTP middleware (CORS, multipart)</td>
        </tr>
        <tr>
          <td><strong>tracing</strong></td>
          <td>0.1</td>
          <td>Structured logging</td>
        </tr>
      </tbody>
    </table>

    <h3>Konsep Algoritma</h3>

    <h4>Sentence-Level TF-IDF</h4>
    <p><strong>Perbedaan dengan TF-IDF Tradisional:</strong></p>
    <table class="comparison-table">
      <thead>
        <tr>
          <th>Aspek</th>
          <th>TF-IDF Tradisional</th>
          <th>Sentence-Level TF-IDF</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td><strong>Granularity</strong></td>
          <td>Per dokumen</td>
          <td><strong>Per kalimat</strong></td>
        </tr>
        <tr>
          <td><strong>TF Calculation</strong></td>
          <td>Term count / total words in document</td>
          <td><strong>Term count / total words in sentence</strong></td>
        </tr>
        <tr>
          <td><strong>IDF Scope</strong></td>
          <td>Document frequency</td>
          <td><strong>Sentence frequency (global)</strong></td>
        </tr>
        <tr>
          <td><strong>Output</strong></td>
          <td>Document similarity score</td>
          <td><strong>Sentence pairs with similarity</strong></td>
        </tr>
        <tr>
          <td><strong>Use Case</strong></td>
          <td>General similarity</td>
          <td><strong>Plagiarism detection</strong></td>
        </tr>
      </tbody>
    </table>

    <p><strong>Term Frequency (Per Sentence):</strong></p>
    <div class="diagram-box">
      $$TF(t, s) = \frac{\text{count of term } t \text{ in sentence }
      s}{\text{total words in sentence } s}$$
    </div>

    <p><strong>Inverse Document Frequency (Global Sentences):</strong></p>
    <div class="diagram-box">
      $$IDF(t) = \log\left(\frac{N_{sentences} + 1}{df(t) + 1}\right) + 1$$
    </div>

    <p>Dimana:</p>
    <ul>
      <li>
        $N_{sentences}$ = total jumlah kalimat dari
        <strong>semua dokumen</strong>
      </li>
      <li>$df(t)$ = jumlah kalimat yang mengandung term $t$</li>
    </ul>

    <p><strong>TF-IDF Score:</strong></p>
    <div class="diagram-box">
      $$TF\text{-}IDF(t, s) = TF(t, s) \times IDF(t)$$
    </div>

    <h4>Cosine Similarity</h4>
    <p>Mengukur sudut antara dua vektor TF-IDF:</p>
    <div class="diagram-box">
      $$\text{similarity}(A, B) = \frac{A \cdot B}{\|A\| \times \|B\|}$$
    </div>

    <p><strong>Hasil:</strong></p>
    <ul>
      <li>
        <strong>≥ 0.85</strong> = Very High Similarity (likely plagiarism)
      </li>
      <li>
        <strong>0.70 - 0.84</strong> = High Similarity (significant overlap)
      </li>
      <li><strong>0.50 - 0.69</strong> = Moderate Similarity</li>
      <li><strong>&lt; 0.50</strong> = Low Similarity</li>
    </ul>

    <h4>Threshold Filtering</h4>
    <p>
      Sistem menggunakan <strong>configurable threshold</strong> (default 0.70):
    </p>
    <ul>
      <li>Hanya sentence pairs dengan similarity ≥ threshold yang disimpan</li>
      <li>Mengurangi false positives</li>
      <li>User dapat adjust sesuai kebutuhan (ketat vs longgar)</li>
    </ul>

    <h4>Global Similarity Score</h4>
    <p>Dihitung sebagai <strong>average dari sentence matches</strong>:</p>
    <div class="diagram-box">
      $$\text{Global Similarity}(Doc_A, Doc_B) = \frac{\sum \text{similarity
      scores}}{|\text{matches}|}$$
    </div>

    <h4>Parallel Processing dengan Rayon</h4>
    <p>
      Sistem menggunakan <strong>Rayon</strong> untuk parallel processing pada
      multi-core CPU:
    </p>
    <p><strong>Pipeline Parallel:</strong></p>
    <div class="diagram-box">
      <pre>
┌────────────────────────────────────────────────┐
│         PARALLEL (per sentence)                │
│  Sentence 1 → Normalize → Tokenize → TF       │
│  Sentence 2 → Normalize → Tokenize → TF       │
│  Sentence N → Normalize → Tokenize → TF       │
└────────────────────────────────────────────────┘
                    ↓
┌────────────────────────────────────────────────┐
│         SINGLE THREAD                          │
│  Compute Global IDF (needs all TFs)            │
└────────────────────────────────────────────────┘
                    ↓
┌────────────────────────────────────────────────┐
│         PARALLEL (per sentence)                │
│  TF1 + IDF → TF-IDF Vector 1                   │
│  TF2 + IDF → TF-IDF Vector 2                   │
│  TFN + IDF → TF-IDF Vector N                   │
└────────────────────────────────────────────────┘
                    ↓
┌────────────────────────────────────────────────┐
│         PARALLEL (pairwise comparison)         │
│  Compare all sentence pairs (cross-doc only)   │
│  Filter by threshold                           │
│  Sort by similarity                            │
└────────────────────────────────────────────────┘
      </pre>
    </div>

    <hr />

    <!-- SCREENSHOT -->
    <h2>Screenshot</h2>

    <h3>1. Running Server</h3>
    <pre><code class="language-bash">$ cargo run --release
   Compiling document-similarity-analyzer v0.1.0
    Finished release [optimized] target(s) in 45.32s
     Running `target/release/document-similarity-analyzer`

2025-12-08T08:00:00.000Z  INFO Server running on 0.0.0.0:3000</code></pre>

    <h3>2. API Request &amp; Response</h3>
    <p><strong>Request:</strong></p>
    <pre><code class="language-bash">curl -X POST http://localhost:3000/api/analyze \
  -F "files=@research_paper.pdf" \
  -F "files=@reference_1.docx" \
  -F "files=@reference_2.txt" \
  -F "threshold=0.75"</code></pre>

    <p><strong>Response:</strong></p>
    <pre><code class="language-json">{
  "metadata": {
    "documents_count": 3,
    "total_sentences": 118,
    "processing_time_ms": 84,
    "threshold": 0.75
  },
  "matches": [
    {
      "source_doc": "research_paper.pdf",
      "source_sentence_index": 20,
      "source_sentence": "Security systems employ computer vision for surveillance and threat detection.",
      "target_doc": "reference_1.docx",
      "target_sentence_index": 20,
      "target_sentence": "Surveillance systems employ computer vision for security and monitoring applications.",
      "similarity": 0.7022883
    }
  ],
  "global_similarity": [
    {
      "docA": "research_paper.pdf",
      "docB": "reference_1.docx",
      "score": 0.0415522
    }
  ]
}</code></pre>

    <h3>3. Running Tests</h3>
    <pre><code class="language-bash">$ cargo test
    Finished test [unoptimized + debuginfo] target(s) in 4.12s
     Running unittests src/lib.rs

running 83 tests
test sentence::tests::test_split_sentences_basic ... ok
test core::tf::tests::test_basic_tf ... ok
test core::idf::tests::test_multiple_documents ... ok
test core::similarity::tests::test_identical_vectors ... ok
test core::sentence_pipeline::tests::test_analyze_two_documents ... ok
... (all 83 tests passed)

test result: ok. 83 passed; 0 failed; 0 ignored</code></pre>

    <hr />

    <!-- KESIMPULAN -->
    <h2>Kesimpulan</h2>

    <h3>Pencapaian Proyek</h3>
    <p>Document Similarity Analyzer berhasil mengimplementasikan:</p>
    <ol>
      <li>
        <strong>Sentence-Level Analysis</strong> untuk plagiarism detection yang
        presisi:
        <ul>
          <li>Identifikasi kalimat spesifik yang mirip antar dokumen</li>
          <li>Response include sentence text untuk frontend highlighting</li>
          <li>Cross-document comparison only (no intra-document)</li>
        </ul>
      </li>
      <li>
        <strong>Multipart File Upload</strong> dengan validasi komprehensif:
        <ul>
          <li>Support PDF, DOCX, TXT</li>
          <li>Max 5 files, 10MB per file, 50MB total</li>
          <li>Automatic text extraction dan sentence splitting</li>
        </ul>
      </li>
      <li>
        <strong>Configurable Threshold</strong> untuk fleksibilitas:
        <ul>
          <li>Default 0.70 (balanced)</li>
          <li>User dapat adjust: ketat (0.85+) atau longgar (0.50-0.65)</li>
          <li>Filter otomatis matches by threshold</li>
        </ul>
      </li>
      <li>
        <strong>Pendekatan Pemrograman Fungsional</strong>:
        <ul>
          <li>Pure functions di seluruh core logic</li>
          <li>
            Immutability (hanya 3 <code>mut</code> untuk sorting API
            requirement)
          </li>
          <li>Function composition dengan iterator chains</li>
          <li>
            Higher-order functions (<code>map</code>, <code>filter</code>,
            <code>fold</code>, <code>flat_map</code>)
          </li>
        </ul>
      </li>
      <li>
        <strong>Parallel Processing</strong> dengan Rayon:
        <ul>
          <li>Sentence normalization &amp; tokenization (parallel)</li>
          <li>TF calculation per sentence (parallel)</li>
          <li>TF-IDF vectorization (parallel)</li>
          <li>Pairwise similarity computation (parallel)</li>
          <li>Performance improvement 4-8x pada multi-core CPU</li>
        </ul>
      </li>
      <li>
        <strong>Comprehensive Testing</strong>:
        <ul>
          <li>83 unit tests covering all modules</li>
          <li>Integration tests untuk API endpoints</li>
          <li>Test coverage untuk edge cases</li>
        </ul>
      </li>
    </ol>

    <h3>Pembelajaran</h3>
    <p>Melalui proyek ini, kami memahami:</p>
    <ul>
      <li>
        <strong>Sentence-level analysis</strong> lebih valuable untuk plagiarism
        detection dibanding document-level
      </li>
      <li>
        <strong>Rust dan pemrograman fungsional</strong> sangat kompatibel —
        ownership system mendorong immutability
      </li>
      <li>
        <strong>Parallel processing</strong> menjadi trivial dengan Rayon ketika
        data immutable
      </li>
      <li>
        <strong>HashMap-based vectors</strong> lebih efficient untuk sparse data
        dibanding dense arrays
      </li>
      <li>
        <strong>Regex-based sentence splitting</strong> simple namun effective
        untuk bahasa Indonesia/Inggris
      </li>
      <li>
        <strong>Threshold tuning</strong> critical untuk balance antara
        precision dan recall
      </li>
    </ul>

    <h3>Perbedaan Sistem Lama vs Baru</h3>
    <table class="comparison-table">
      <thead>
        <tr>
          <th>Aspek</th>
          <th>Sistem Lama (Document-Level)</th>
          <th>Sistem Baru (Sentence-Level)</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td><strong>Granularity</strong></td>
          <td>Per dokumen</td>
          <td><strong>Per kalimat</strong></td>
        </tr>
        <tr>
          <td><strong>Output</strong></td>
          <td>Similarity matrix</td>
          <td><strong>Matched sentence pairs + global score</strong></td>
        </tr>
        <tr>
          <td><strong>Frontend</strong></td>
          <td>Tidak bisa highlight</td>
          <td><strong>Bisa highlight exact sentences</strong></td>
        </tr>
        <tr>
          <td><strong>Use Case</strong></td>
          <td>General similarity</td>
          <td><strong>Plagiarism detection dengan evidence</strong></td>
        </tr>
        <tr>
          <td><strong>API</strong></td>
          <td>JSON array dokumen</td>
          <td><strong>Multipart file upload (PDF/DOCX/TXT)</strong></td>
        </tr>
        <tr>
          <td><strong>Threshold</strong></td>
          <td>Fixed</td>
          <td><strong>Configurable (0.0-1.0)</strong></td>
        </tr>
        <tr>
          <td><strong>Response</strong></td>
          <td>Matrix saja</td>
          <td><strong>Metadata + matches + global similarity</strong></td>
        </tr>
      </tbody>
    </table>

    <h3>Pengembangan Selanjutnya</h3>
    <p>Potensi improvement di masa depan:</p>
    <ul>
      <li>
        <strong>Stemming</strong> untuk bahasa Indonesia (Sastrawi library)
      </li>
      <li><strong>Stop words removal</strong> untuk meningkatkan akurasi</li>
      <li>
        <strong>Sentence embeddings</strong> dengan transformer models
        (BERT/RoBERTa)
      </li>
      <li><strong>WebSocket</strong> untuk real-time progress updates</li>
      <li>
        <strong>Frontend dashboard</strong> untuk visualisasi heatmap dan
        highlighting
      </li>
      <li><strong>Batch processing</strong> untuk analisis corpus besar</li>
      <li><strong>Caching IDF</strong> untuk corpus yang tidak berubah</li>
      <li><strong>Support more formats</strong> (ODT, RTF, HTML)</li>
    </ul>

    <hr />
  </body>
</html>
